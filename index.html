<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Debarpan Bhattacharya</title>
  
  <meta name="author" content="Debarpan Bhattacharya">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Debarpan Bhattacharya</name>
              </p>
              <p>I am an incoming PhD student (starting January, 2023) at <a href="https://iisc.ac.in/">Indian Institute of Science (IISc)</a>, Bangalore, India. I was an MTech(Research) student at IISc from 2020 to 2022. Before joining at IISc, I spent amazing four years at <a href="http://www.jaduniv.edu.in/">Jadavpur University</a>, Kolkata, while pursuing my bachelor's in Electrical Engineering. 
              </p>
              <p>
                At IISc, I am associated with <a href="http://leap.ee.iisc.ac.in/">LEAP lab</a> under the guidance of the coolest :) <a href="http://leap.ee.iisc.ac.in/sriram/">Prof. Sriram Ganapathy</a>. I've been working on explainable AI- specifically on post-hoc model-agnostic explainability methods, bias and fairness. I have also been associated with <a href="https://coswara.iisc.ac.in/">project COSWARA</a>, one of the prominent responses of IISc to limit the spread of COVID-19. It shows that COVID-19 can be effectively screened using respiratory sounds like cough, breathing and speech [<a href="https://github.com/iiscleap/Coswara-Data">project repo</a>]. Check out our publications for more details.
              </p>
              <p>
                During my bachelor's, I have worked on multiple signal processing based projects with sensing and healthcare applications. I was fortunate to receive close mentorship from <a href="https://scholar.google.com/citations?user=4QDUROsAAAAJ&hl=en">Prof. Sugata Munshi</a>, <a href="https://www.researchgate.net/scientific-contributions/Biswajit-Bhattacharyya-2083293274">Prof. Biswajit Bhattacharyya</a> and <a href="https://cse.iitkgp.ac.in/~smisra/">Prof. Sudip Misra</a>.
              </p>
              <p style="text-align:center">
                <a href="www.linkedin.com/in/debarpan98">LinkedIn</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=cc-xQxIAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/DebarpanBhatta8">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/debarpanbhatta123">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/photo-website-crop.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/photo-website-crop.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm broadly interested in explainable AI, bias, fairness and deep learning for audio and speech processing. Check out my publications for further details.
              </p>
              <p>
                The <a href="https://coswara.iisc.ac.in/">COSWARA web application</a> can now generate COVID-19 probability of a subject in real-time. Spend 3-4 minutes to record your respiratory sounds and get COVID-19 infection probability score!
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Contact</heading>
            <p>
              If you are working on projects under the umbrella of audio and speech processing and/or explainable AI, and want to have a chat, feel free to drop a mail at <a href="mailto:debarpanb@iisc.ac.in">debarpanb[at]iisc[dot]ac[dot]in</a> / <a href="mailto:debarpanbhatta123@gmail.com">debarpanbhatta123[at]gmail[dot]com</a> . 
            </p>
          </td>
        </tr>
      </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Resume</heading>
              <p>
                <a href="data/CV_Debarpan_10-10-22.pdf">download</a> [last updated: 10/10/2022]
              </p>
            </td>
          </tr>
        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Recent Updates</heading>
              <p>
                <b>June 2023:</b> <a href="https://www.nature.com/articles/s41597-023-02266-0">"Coswara: A respiratory sounds and symptoms dataset for remote screening of SARS-CoV-2 infection"</a> is published with open access in Nature Scientific Data (<papertitle style="color:red;">5-year IF: 11.5</papertitle>).
              </p>
              <p>
                <b>Jan 2023:</b> Journal paper "Coswara: A respiratory sounds and symptoms dataset for remote screening of SARS-CoV-2 infection" is accepted in Nature Scientific Data.
              </p>
              <p>
                <b>Jan 2023:</b> Submitted MTech(Research) thesis and rejoined to PhD at LEAP Lab, IISc.
              </p>
              <p>
                <b>Sep 2022:</b> Selected for Doctoral Symposium and Demonstrations tracks in AI-ML Systems 2022 to be held in Bangalore.
              </p>
              <p>
                <b>June 2022:</b> 2 full papers and 1 Show and Tell paper accepted in INTERSPEECH 2022 to be held in South Korea.
              </p>
              <p>
                <b>Jan 2022:</b> 1 paper accepted in ICASSP 2022 to be held in Singapore.
              </p>
              <p>
                <b>Oct 2020:</b> Started pursuing MTech(Research) at IISC Bangalore.
              </p>
            </td>
          </tr>
        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Achievements</heading>
              <p>
                <b>Oct 2022:</b> Was awarded IEEE-HKN Mu Xi through IEEE-IISc student branch.
              </p>
              <p>
                <b>July 2022:</b> Received ISCA travel grant to attend INTERSPEECH 2022 in South Korea.
              </p>
              <p>
                <b>Dec 2021:</b> Received <b>Best Paper award</b> in IEEE INDICON 2021 for the paper on Huffman coding based ECG signal compression [<a href="https://ieeexplore.ieee.org/abstract/document/9691675">click</a>].
              </p>
              <p>
                <b>Sep 2020:</b> Received B N Paul Memorial Silver Medal for receiving highest marks in "Electric Drives" among 111 students.
              </p>
              <p>
                <b>Jan 2019:</b> Selected for Summer Research Fellowship(SRF) by Indian Academy of Science(IAS) among about 110 students throughout India.
              </p>
            </td>
          </tr>
        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
            <tr onmouseout="img_stop()" onmouseover="img_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='paper_image'>
                    <img src='images/nature_sdata.png' width="160"></div>
                  <img src='images/nature_sdata.png' width="160"></div>
                <script type="text/javascript">
                  function img_start() {
                    document.getElementById('paper_image').style.opacity = "1";
                  }

                  function img_stop() {
                    document.getElementById('paper_image').style.opacity = "0";
                  }
                  img_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle style="color:red;">[Impact Factor: 11.5] </papertitle><papertitle>Coswara: A respiratory sounds and symptoms dataset for remote screening of SARS-CoV-2 infection</papertitle>
                <br>
                <strong>Debarpan Bhattacharya</strong>, Neeraj Kumar Sharma, Debottam Dutta, Srikanth Raj Chetupalli, Pravin Mote, Sriram Ganapathy, C. Chandrakiran, Sahiti Nori, K. K. Suhail, Sadhana Gonuguntla, Murali Alagesan

                <br>
                <em>Nature Scientific Data</em>, 2023
                <br>
                <a href="https://www.nature.com/articles/s41597-023-02266-0">paper</a>
                <p></p>
                <p>
                  This paper presents the Coswara dataset, a dataset containing diverse set of respiratory sounds and rich meta-data, recorded between April-2020 and February-2022 from 2635 individuals (1819 SARS-CoV-2 negative, 674 positive, and 142 recovered subjects). The respiratory sounds contained nine sound categories associated with variants of breathing, cough and speech. A rich set of metadata is also present.
                </p>
              </td>
            </tr>
            <tr onmouseout="img_stop()" onmouseover="img_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='paper_image'>
                    <img src='images/strain-paper-image.png' width="160"></div>
                  <img src='images/strain-paper-image.png' width="160"></div>
                <script type="text/javascript">
                  function img_start() {
                    document.getElementById('paper_image').style.opacity = "1";
                  }

                  function img_stop() {
                    document.getElementById('paper_image').style.opacity = "0";
                  }
                  img_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Analyzing the impact of SARS-CoV-2 variants on respiratory sound signals</papertitle>
                <br>
                <strong>Debarpan Bhattacharya</strong>, Debottam Dutta, Neeraj Kumar Sharma, Srikanth Raj Chetupalli, Pravin Mote, Sriram Ganapathy, Chandrakiran C, Sahiti Nori, Suhail K K, Sadhana Gonuguntla, Murali Alagesan

                <br>
                <em>INTERSPEECH</em>, 2022
                <br>
                <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/bhattacharya22_interspeech.pdf">paper</a>
                <p></p>
                <p>
                  We analyze the Coswara dataset which is collected from three subject pools, namely, i) healthy, ii) COVID-19 subjects recorded during the delta variant dominant period, and iii) data from COVID-19 subjects recorded during the omicron surge. Our findings suggest that multiple sound categories, such as cough, breathing, and speech, indicate significant acoustic feature differences when comparing COVID-19 subjects with omicron and delta variants.
                </p>
              </td>
            </tr>
            <tr onmouseout="img_stop()" onmouseover="img_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='paper_image'>
                    <img src='images/coswara-app-image.png' width="160"></div>
                  <img src='images/coswara-app-image.png' width="160"></div>
                <script type="text/javascript">
                  function img_start() {
                    document.getElementById('paper_image').style.opacity = "1";
                  }

                  function img_stop() {
                    document.getElementById('paper_image').style.opacity = "0";
                  }
                  img_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Coswara: A website application enabling COVID-19 screening by analysing respiratory sound samples and health symptoms</papertitle>
                <br>
                <strong>Debarpan Bhattacharya</strong>, Debottam Dutta, Neeraj Kumar Sharma, Srikanth Raj Chetupalli, Pravin Mote, Sriram Ganapathy, Chandrakiran C, Sahiti Nori, Suhail K K, Sadhana Gonuguntla, Murali Alagesan

                <br>
                <em>Show and Tell, INTERSPEECH</em>, 2022
                <br>
                <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/bhattacharya22b_interspeech.pdf">short paper</a> / <a href="https://www.youtube.com/watch?v=9CltKLE_HIs">video</a>
                <p></p>
                <p>
                  A user using this service can log into a website using any device connected to the internet, provide there current health symptom information and record few sound sampled corresponding to breathing, cough, and speech. Within a minute of analysis of this information on a cloud server the website tool will output a COVID-19 probability score to the user.
                </p>
              </td>
            </tr>
            <tr onmouseout="img_stop()" onmouseover="img_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='paper_image'>
                    <img src='images/rep-learning-is22-image.png' width="160"></div>
                  <img src='images/rep-learning-is22-image.png' width="160"></div>
                <script type="text/javascript">
                  function img_start() {
                    document.getElementById('paper_image').style.opacity = "1";
                  }

                  function img_stop() {
                    document.getElementById('paper_image').style.opacity = "0";
                  }
                  img_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle style="color:red;">[Oral presentation] </papertitle><papertitle>Acoustic Representation Learning on Breathing and Speech Signals for COVID-19 Detection</papertitle>
                <br>
                Debottam Dutta, <strong>Debarpan Bhattacharya</strong>, Sriram Ganapathy, Amir Hossein Poorjam, Deepak Mittal, Maneesh Singh

                <br>
                <em>INTERSPEECH</em>, 2022
                <br>
                <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/dutta22b_interspeech.pdf">paper</a> / <a href="https://github.com/iiscleap/acoustic_repLearn_dicova2">code</a>
                <p></p>
                <p>
                  We describe an approach for representation learning of audio signals for the task of COVID-19 detection. The raw audio samples are processed with a bank of 1-D convolutional filters that are parameterized as cosine modulated Gaussian functions. The relevance weighting emphasizes the key regions of the time-frequency decomposition of the filtered output. The subsequent layers of the model consist of a recurrent architecture.
                </p>
              </td>
            </tr>
            <tr onmouseout="img_stop()" onmouseover="img_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='paper_image'>
                    <img src='images/system-report-verisk.png' width="160"></div>
                  <img src='images/system-report-verisk.png' width="160"></div>
                <script type="text/javascript">
                  function img_start() {
                    document.getElementById('paper_image').style.opacity = "1";
                  }

                  function img_stop() {
                    document.getElementById('paper_image').style.opacity = "0";
                  }
                  img_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>Svadhyaya system for the Second Diagnosing COVID-19 using Acoustics Challenge 2021</papertitle>
                <br>
                Deepak Mittal, Amir H Poorjam, Debottam Dutta, <strong>Debarpan Bhattacharya</strong>, Zemin Yu, Sriram Ganapathy, Maneesh Singh
                <br>
                <em>Pre-print</em>, 2022
                <br>
                <a href="https://arxiv.org/abs/2206.05462">arxiv</a>
                <p></p>
                <p>
                  This report describes the system of Team Svadhyaya used for detecting COVID-19 positives using three different acoustic modalities, namely speech, breathing, and cough in the second DiCOVA challenge. The system reached the blind test AUCs of 86.41, 77.60, and 84.55, in the breathing, cough, and speech tracks, respectively, and the AUC of 85.37 in the fusion of these three tracks.
                </p>
              </td>
            </tr>
            <tr onmouseout="img_stop()" onmouseover="img_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='paper_image'>
                    <img src='images/icassp22-paper-image.png' width="160"></div>
                  <img src='images/icassp22-paper-image.png' width="160"></div>
                <script type="text/javascript">
                  function img_start() {
                    document.getElementById('paper_image').style.opacity = "1";
                  }

                  function img_stop() {
                    document.getElementById('paper_image').style.opacity = "0";
                  }
                  img_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>The Second Dicova Challenge: Dataset and Performance Analysis for Diagnosis of Covid-19 Using Acoustics</papertitle>
                <br>
                Neeraj Kumar Sharma, Srikanth Raj Chetupalli, <strong>Debarpan Bhattacharya</strong>, Debottam Dutta, Pravin Mote, Sriram Ganapathy
                <br>
                <em>ICASSP</em>, 2022
                <br>
                <a href="https://ieeexplore.ieee.org/abstract/document/9747188">paper</a> / <a href="https://arxiv.org/abs/2110.01177">arxiv</a> / <a href="https://sigport.org/sites/default/files/docs/ppt_icassp22_v2_1.pdf">slides</a> 
                <p></p>
                <p>
                  The Second Diagnosis of COVID-19 using Acoustics (DiCOVA) Challenge aimed at accelerating the research in acoustics based detection of COVID-19. In this paper, we present an overview of the challenge, the rationale for the data collection and the baseline system. Further, a performance analysis for the systems submitted by the 21 participating teams in the leaderboard is also presented.
                </p>
              </td>
            </tr>
            <tr onmouseout="img_stop()" onmouseover="img_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='paper_image'>
                    <img src='images/huffman-paper-image.png' width="160"></div>
                  <img src='images/huffman-paper-image.png' width="160"></div>
                <script type="text/javascript">
                  function img_start() {
                    document.getElementById('paper_image').style.opacity = "1";
                  }

                  function img_stop() {
                    document.getElementById('paper_image').style.opacity = "0";
                  }
                  img_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle style="color:red;">[Best Paper Award]</papertitle><papertitle> Huffman Coding based ECG Processing For Compression-Distortion Tradeoff</papertitle>
                <br>
                <strong>Debarpan Bhattacharya</strong>
                <br>
                <em>IEEE INDICON</em>, 2021
                <br>
                <a href="https://ieeexplore.ieee.org/abstract/document/9691675">paper</a>
                <p></p>
                <p>
                  In our proposed approach, a noble huffman coding based compression technique for ECG signal is proposed. It offers high compression ratio (CR) with minimal percentage mean square difference (PRD). Additionally, the algorithm offers flexibility to decrease PRD value at the cost of CR, obtained by tuning a single parameter.
                </p>
              </td>
            </tr>
            <tr onmouseout="img_stop()" onmouseover="img_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='paper_image'>
                    <img src='images/indicon-temp-sensor-image.png' width="160"></div>
                  <img src='images/indicon-temp-sensor-image.png' width="160"></div>
                <script type="text/javascript">
                  function img_start() {
                    document.getElementById('paper_image').style.opacity = "1";
                  }

                  function img_stop() {
                    document.getElementById('paper_image').style.opacity = "0";
                  }
                  img_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>Pulse Train Modulation And ANN Based Temperature Sensor With Semi-automatic Calibration</papertitle>
                <br>
                Pranabendra Prasad Chandra, <strong>Debarpan Bhattacharya</strong>, Biswajit Bhattacharyya, Sugata Munshi
                <br>
                <em>IEEE INDICON</em>, 2021
                <br>
                <a href="https://ieeexplore.ieee.org/abstract/document/9691651">paper</a>
                <p></p>
                <p>
                  ANN based temperature measurement system involving thermocouples with provision of semi-automatic calibration. The proposed measurement system outperforms all the thermocouple-based temperature measurement techniques proposed in recent literature, in terms of accuracy, reliability, cost, and potential for embedded system application.
                </p>
              </td>
            </tr>
            <tr onmouseout="img_stop()" onmouseover="img_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='paper_image'>
                    <img src='images/acm-tiot-image.png' width="160"></div>
                  <img src='images/acm-tiot-image.png' width="160"></div>
                <script type="text/javascript">
                  function img_start() {
                    document.getElementById('paper_image').style.opacity = "1";
                  }

                  function img_stop() {
                    document.getElementById('paper_image').style.opacity = "0";
                  }
                  img_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>IDeA: IoT-based autonomous aerial demarcation and path planning for precision agriculture with UAVs</papertitle>
                <br>
                <strong>Debarpan Bhattacharya</strong>, Sudip Misra, Nidhi Pathak, Anandarup Mukherjee
                <br>
                <em>ACM Transactions on Internet of Things</em>, 2020
                <br>
                <a href="https://dl.acm.org/doi/abs/10.1145/3379930">paper</a>
                <p></p>
                <p>
                  We proposed an autonomous and onboard image-based agricultural land demarcation and path-planning system‚ÄîIDeA (IoT-Based Autonomous Aerial Demarcation and Path Planning for Precision Agriculture) with Unmanned Aerial Vehicles (UAVs).
                </p>
              </td>
            </tr>
            <tr onmouseout="img_stop()" onmouseover="img_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='paper_image'>
                    <img src='images/calcon-paper-bd.png' width="160"></div>
                  <img src='images/calcon-paper-bd.png' width="160">
                </div>
                <script type="text/javascript">
                  function img_start() {
                    document.getElementById('paper_image').style.opacity = "1";
                  }

                  function img_stop() {
                    document.getElementById('paper_image').style.opacity = "0";
                  }
                  img_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>Optimized Thermocouple Temperature Sensor using
                    555 Timer and ANN Based Linearization</papertitle>
                <br>
                <strong>Debarpan Bhattacharya</strong>, Pranabendra Prasad Chandra, Biswajit Bhattacharyya, Sugata Munshi
                <br>
                <em>IEEE CALCON</em>, 2020
                <br>
                <a href="https://ieeexplore.ieee.org/abstract/document/9106536/">paper</a>
                <p></p>
                <p>
                  Two-stage linearization scheme for thermocouple based temperature sensing. The first stage involves IC555 based astable multivibrator and the second stage is fully connected neural network based regression.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Experience</heading>
              <p>
                <b>May 2019-July 2019:</b> Summer internship at <a href="https://www.iitb.ac.in/">IIT Bombay</a>.
              </p>
              <p>
                <b>Jun 2018:</b> Summer training at <a href="https://www.cesc.co.in/home">CESC</a>, Kolkata.
              </p>
              <p>
                <b>Dec 2017-Jan 2018:</b> Winter internship at <a href="https://www.vecc.gov.in/">Variable Energy Cyclotron Centre</a>, Kolkata.
              </p>
              <p>
                <b>Dec 2016-Aug 2017:</b> Summer internship at <a href="http://cse.iitkgp.ac.in/~smisra/swan/">SWAN lab</a>, <a href="http://iitkgp.ac.in//">IIT Kharagpur</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Teaching</heading>
              <p>
                <b>Head Teaching Assistant:</b> E9:205: Machine Learning for Signal Processing, IISc
              </p>
              <p>
                <b>Teaching Assistant:</b> AI for Digital Health and Imaging, CCE, IISc
              </p>
            </td>
          </tr>
        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Position(s) of Responsibility</heading>
              <p>
                <b>Chair:</b> IEEE Signal Processing Society Students Chapter, IISc
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:45%;vertical-align:middle">
            </td>
            <td style="padding:20px;width:55%;vertical-align:middle">
              <!-- <div> Thanks to <a href="https://jonbarron.info/">Jon Barron</a> for the template.</div> -->
              Template: <a href="https://jonbarron.info/">John Barron</a>
            </td>
          </tr>
        </tbody></table>        
</body>

</html>
